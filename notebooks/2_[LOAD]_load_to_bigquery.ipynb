{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "557bd78a",
   "metadata": {},
   "source": [
    "# Notebook 2 : Chargement des Données vers BigQuery (LOAD)\n",
    "\n",
    "## Objectif\n",
    "\n",
    "Ce notebook permet de **charger les données depuis Google Cloud Storage (GCS) vers BigQuery** pour créer la couche \"silver\" du pipeline ETL. \n",
    "\n",
    "Les données brutes stockées dans GCS (couche \"bronze\") sont chargées dans BigQuery.\n",
    "\n",
    "## Prérequis\n",
    "\n",
    "Avant d'exécuter ce notebook, assurez-vous d'avoir :\n",
    "\n",
    "1. **Exécuté le notebook `1_[EXTRACT]_ingest_to_gcs.ipynb`** pour avoir des données dans GCS\n",
    "2. **Fichier `.env` configuré** avec les variables d'environnement nécessaires\n",
    "3. **Service Account** avec les permissions BigQuery (`BigQuery Data Editor`, `BigQuery Job User`)\n",
    "4. **Packages Python installés** : `google-cloud-bigquery`, `google-cloud-storage`, `pandas`, etc.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d962f99c",
   "metadata": {},
   "source": [
    "## 1 - Configuration et Authentification\n",
    "\n",
    "Cette section configure l'environnement et établit la connexion avec BigQuery et GCS.\n",
    "\n",
    "**Étapes :**\n",
    "- Import des bibliothèques nécessaires\n",
    "- Chargement des variables d'environnement depuis `.env`\n",
    "- Authentification avec le Service Account\n",
    "- Création des clients BigQuery et GCS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac220fb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] - Configuration et imports terminés\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from google.cloud import bigquery, storage\n",
    "from google.oauth2 import service_account\n",
    "\n",
    "ROOT = Path.cwd().parent\n",
    "sys.path.append(str(ROOT))\n",
    "\n",
    "from src.bq_utils import (\n",
    "    load_csv_from_gcs,\n",
    "    load_parquet_from_gcs,\n",
    ")\n",
    "\n",
    "# Configuration\n",
    "load_dotenv()\n",
    "\n",
    "PROJECT_ID = os.getenv(\"PROJECT_ID\")\n",
    "SA_PATH = ROOT / os.getenv(\"GOOGLE_APPLICATION_CREDENTIALS\")\n",
    "BUCKET_NAME = os.getenv(\"BUCKET_NAME\")\n",
    "DATASET_ID = \"silver\"\n",
    "\n",
    "# Authentification\n",
    "creds = service_account.Credentials.from_service_account_file(SA_PATH)\n",
    "bq_client = bigquery.Client(project=PROJECT_ID, credentials=creds)\n",
    "storage_client = storage.Client(project=PROJECT_ID, credentials=creds)\n",
    "\n",
    "print(\"[OK] - Configuration et imports terminés\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f1044d",
   "metadata": {},
   "source": [
    "### 1.1 - Création du Dataset BigQuery\n",
    "\n",
    "Création du dataset \"silver\" s'il n'existe pas déjà. Le dataset est l'équivalent d'un schéma dans une base de données relationnelle.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c8781b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] - Dataset silver existe déjà\n"
     ]
    }
   ],
   "source": [
    "# Création du dataset s'il n'existe pas\n",
    "dataset_ref = bq_client.dataset(DATASET_ID)\n",
    "try:\n",
    "    bq_client.get_dataset(dataset_ref)\n",
    "    print(f\"[OK] - Dataset {DATASET_ID} existe déjà\")\n",
    "except Exception:\n",
    "    dataset = bigquery.Dataset(dataset_ref)\n",
    "    dataset.location = \"US\"\n",
    "    dataset = bq_client.create_dataset(dataset, exists_ok=True)\n",
    "    print(f\"[OK] - Dataset {DATASET_ID} créé\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2c77f9",
   "metadata": {},
   "source": [
    "## 2 - Chargement des Tables de Dimension\n",
    "\n",
    "Les tables de dimension contiennent les données de référence qui seront utilisées pour enrichir les tables de fait. Elles sont généralement stables dans le temps.\n",
    "\n",
    "---\n",
    "\n",
    "### 2.1 - Table `dim_gare` (Emplacement des Gares)\n",
    "\n",
    "Cette table contient les informations géographiques et descriptives de toutes les gares d'Île-de-France.\n",
    "\n",
    "**Caractéristiques :**\n",
    "- **Format source** : Parquet (depuis GCS)\n",
    "- **Schéma** : Défini manuellement avec clé primaire `id_gares`\n",
    "- **Types de données** : Géographie (GEOGRAPHY), entiers, chaînes de caractères\n",
    "- **Clé primaire** : `id_gares` (mode REQUIRED)\n",
    "\n",
    "**Note** : Le schéma manuel permet de contrôler précisément les types de données, notamment pour les colonnes géographiques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2fb26fc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[...] - Chargement de gs://bronze-sncf-etl-idfm-reims/bronze/emplacement-des-gares-idf/emplacement-des-gares-idf.parquet vers idfm-etl-reims-0224dy2025dy.silver.gares...\n",
      "[OK] - 1240 lignes chargées dans idfm-etl-reims-0224dy2025dy.silver.gares\n",
      "[OK] - Taille: 0.62 MB\n",
      "[OK] - Clé primaire: id_gares\n"
     ]
    }
   ],
   "source": [
    "# Chargement direct depuis GCS (bronze) vers BigQuery (silver) avec schéma manuel\n",
    "gcs_path_gares = \"bronze/emplacement-des-gares-idf/emplacement-des-gares-idf.parquet\"\n",
    "\n",
    "# Définition du schéma manuel avec clé primaire (id_gares)\n",
    "schema_gares = [\n",
    "    bigquery.SchemaField(\"geo_point_2d\", \"GEOGRAPHY\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"geo_shape\", \"GEOGRAPHY\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"id_gares\", \"INTEGER\", mode=\"REQUIRED\", description=\"Clé primaire\"),\n",
    "    bigquery.SchemaField(\"nom_gares\", \"STRING\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"nom_so_gar\", \"STRING\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"nom_su_gar\", \"STRING\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"id_ref_zdc\", \"INTEGER\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"nom_zdc\", \"STRING\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"id_ref_zda\", \"INTEGER\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"nom_zda\", \"STRING\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"idrefliga\", \"STRING\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"idrefligc\", \"STRING\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"res_com\", \"STRING\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"indice_lig\", \"STRING\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"mode\", \"STRING\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"tertrain\", \"STRING\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"terrer\", \"STRING\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"termetro\", \"STRING\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"tertram\", \"STRING\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"terval\", \"STRING\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"exploitant\", \"STRING\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"idf\", \"INTEGER\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"principal\", \"INTEGER\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"x\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"y\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"picto\", \"STRING\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"nom_iv\", \"STRING\", mode=\"NULLABLE\"),\n",
    "]\n",
    "\n",
    "table_id = load_parquet_from_gcs(\n",
    "    gcs_path=gcs_path_gares,\n",
    "    table_name=\"gares\",\n",
    "    bq_client=bq_client,\n",
    "    project_id=PROJECT_ID,\n",
    "    dataset_id=DATASET_ID,\n",
    "    bucket_name=BUCKET_NAME,\n",
    "    schema=schema_gares,\n",
    "    primary_key=\"id_gares\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2df54d0",
   "metadata": {},
   "source": [
    "### 2.2 - Vérification de la Table `dim_gare`\n",
    "\n",
    "Après le chargement, on vérifie que les données ont été correctement chargées en :\n",
    "- Affichant le nombre de lignes\n",
    "- Listant les colonnes et leurs types\n",
    "- Afficant un aperçu des données (5 premières lignes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6688f378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] - Nombre total de lignes: 1240\n",
      "[OK] - Colonnes:\n",
      "  - geo_point_2d: GEOGRAPHY\n",
      "  - geo_shape: GEOGRAPHY\n",
      "  - id_gares: INTEGER\n",
      "  - nom_gares: STRING\n",
      "  - nom_so_gar: STRING\n",
      "  - nom_su_gar: STRING\n",
      "  - id_ref_zdc: INTEGER\n",
      "  - nom_zdc: STRING\n",
      "  - id_ref_zda: INTEGER\n",
      "  - nom_zda: STRING\n",
      "  - idrefliga: STRING\n",
      "  - idrefligc: STRING\n",
      "  - res_com: STRING\n",
      "  - indice_lig: STRING\n",
      "  - mode: STRING\n",
      "  - tertrain: STRING\n",
      "  - terrer: STRING\n",
      "  - termetro: STRING\n",
      "  - tertram: STRING\n",
      "  - terval: STRING\n",
      "  - exploitant: STRING\n",
      "  - idf: INTEGER\n",
      "  - principal: INTEGER\n",
      "  - x: FLOAT\n",
      "  - y: FLOAT\n",
      "  - picto: STRING\n",
      "  - nom_iv: STRING\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Claudy LINCY\\Desktop\\M2_SEP\\Outils Big data\\m2-univ-reims-sep-cs-etl-sncf-gcp\\venv\\Lib\\site-packages\\google\\cloud\\bigquery\\table.py:1994: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[OK] - Aperçu des données (5 premières lignes):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geo_point_2d</th>\n",
       "      <th>geo_shape</th>\n",
       "      <th>id_gares</th>\n",
       "      <th>nom_gares</th>\n",
       "      <th>nom_so_gar</th>\n",
       "      <th>nom_su_gar</th>\n",
       "      <th>id_ref_zdc</th>\n",
       "      <th>nom_zdc</th>\n",
       "      <th>id_ref_zda</th>\n",
       "      <th>nom_zda</th>\n",
       "      <th>...</th>\n",
       "      <th>termetro</th>\n",
       "      <th>tertram</th>\n",
       "      <th>terval</th>\n",
       "      <th>exploitant</th>\n",
       "      <th>idf</th>\n",
       "      <th>principal</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>picto</th>\n",
       "      <th>nom_iv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>POINT(2.53313065657104 48.6810166163427)</td>\n",
       "      <td>POINT(2.53313065657104 48.6810166163427)</td>\n",
       "      <td>105</td>\n",
       "      <td>Boussy-Saint-Antoine</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>62596</td>\n",
       "      <td>Boussy-Saint-Antoine</td>\n",
       "      <td>47924</td>\n",
       "      <td>Boussy-Saint-Antoine</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SNCF</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>665628.8216</td>\n",
       "      <td>6.842419e+06</td>\n",
       "      <td>{\"thumbnail\": true, \"filename\": \"RER_D.svg\", \"...</td>\n",
       "      <td>Boussy-Saint-Antoine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>POINT(2.37667281850699 48.4344906128629)</td>\n",
       "      <td>POINT(2.37667281850699 48.4344906128629)</td>\n",
       "      <td>106</td>\n",
       "      <td>Boutigny</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>59565</td>\n",
       "      <td>Boutigny</td>\n",
       "      <td>47895</td>\n",
       "      <td>Boutigny</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SNCF</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>653894.1827</td>\n",
       "      <td>6.815094e+06</td>\n",
       "      <td>{\"thumbnail\": true, \"filename\": \"RER_D.svg\", \"...</td>\n",
       "      <td>Boutigny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>POINT(2.57207366273574 48.5297469185765)</td>\n",
       "      <td>POINT(2.57207366273574 48.5297469185765)</td>\n",
       "      <td>85</td>\n",
       "      <td>Boissise-le-Roi</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>61943</td>\n",
       "      <td>Boissise-le-Roi</td>\n",
       "      <td>45763</td>\n",
       "      <td>Boissise-le-Roi</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SNCF</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>668404.6619</td>\n",
       "      <td>6.825587e+06</td>\n",
       "      <td>{\"thumbnail\": true, \"filename\": \"RER_D.svg\", \"...</td>\n",
       "      <td>Boissise-le-Roi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>POINT(2.59455181600761 48.5649494956709)</td>\n",
       "      <td>POINT(2.59455181600761 48.5649494956709)</td>\n",
       "      <td>135</td>\n",
       "      <td>Cesson</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>62176</td>\n",
       "      <td>Cesson</td>\n",
       "      <td>42516</td>\n",
       "      <td>Cesson</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SNCF</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>670084.3833</td>\n",
       "      <td>6.829491e+06</td>\n",
       "      <td>{\"thumbnail\": true, \"filename\": \"RER_D.svg\", \"...</td>\n",
       "      <td>Cesson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>POINT(2.34701268723876 48.8618222727981)</td>\n",
       "      <td>POINT(2.34701268723876 48.8618222727981)</td>\n",
       "      <td>170</td>\n",
       "      <td>Châtelet-Les Halles</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>474151</td>\n",
       "      <td>Châtelet les Halles</td>\n",
       "      <td>45102</td>\n",
       "      <td>Châtelet les Halles</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>RATP</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>652093.2251</td>\n",
       "      <td>6.862619e+06</td>\n",
       "      <td>{\"thumbnail\": true, \"filename\": \"RER_D.svg\", \"...</td>\n",
       "      <td>Châtelet-Les Halles</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               geo_point_2d  \\\n",
       "0  POINT(2.53313065657104 48.6810166163427)   \n",
       "1  POINT(2.37667281850699 48.4344906128629)   \n",
       "2  POINT(2.57207366273574 48.5297469185765)   \n",
       "3  POINT(2.59455181600761 48.5649494956709)   \n",
       "4  POINT(2.34701268723876 48.8618222727981)   \n",
       "\n",
       "                                  geo_shape  id_gares             nom_gares  \\\n",
       "0  POINT(2.53313065657104 48.6810166163427)       105  Boussy-Saint-Antoine   \n",
       "1  POINT(2.37667281850699 48.4344906128629)       106              Boutigny   \n",
       "2  POINT(2.57207366273574 48.5297469185765)        85       Boissise-le-Roi   \n",
       "3  POINT(2.59455181600761 48.5649494956709)       135                Cesson   \n",
       "4  POINT(2.34701268723876 48.8618222727981)       170   Châtelet-Les Halles   \n",
       "\n",
       "  nom_so_gar nom_su_gar  id_ref_zdc               nom_zdc  id_ref_zda  \\\n",
       "0       None       None       62596  Boussy-Saint-Antoine       47924   \n",
       "1       None       None       59565              Boutigny       47895   \n",
       "2       None       None       61943       Boissise-le-Roi       45763   \n",
       "3       None       None       62176                Cesson       42516   \n",
       "4       None       None      474151   Châtelet les Halles       45102   \n",
       "\n",
       "                nom_zda  ... termetro tertram terval exploitant idf principal  \\\n",
       "0  Boussy-Saint-Antoine  ...        0       0      0       SNCF   1         0   \n",
       "1              Boutigny  ...        0       0      0       SNCF   1         0   \n",
       "2       Boissise-le-Roi  ...        0       0      0       SNCF   1         0   \n",
       "3                Cesson  ...        0       0      0       SNCF   1         0   \n",
       "4   Châtelet les Halles  ...        0       0      0       RATP   1         1   \n",
       "\n",
       "             x             y  \\\n",
       "0  665628.8216  6.842419e+06   \n",
       "1  653894.1827  6.815094e+06   \n",
       "2  668404.6619  6.825587e+06   \n",
       "3  670084.3833  6.829491e+06   \n",
       "4  652093.2251  6.862619e+06   \n",
       "\n",
       "                                               picto                nom_iv  \n",
       "0  {\"thumbnail\": true, \"filename\": \"RER_D.svg\", \"...  Boussy-Saint-Antoine  \n",
       "1  {\"thumbnail\": true, \"filename\": \"RER_D.svg\", \"...              Boutigny  \n",
       "2  {\"thumbnail\": true, \"filename\": \"RER_D.svg\", \"...       Boissise-le-Roi  \n",
       "3  {\"thumbnail\": true, \"filename\": \"RER_D.svg\", \"...                Cesson  \n",
       "4  {\"thumbnail\": true, \"filename\": \"RER_D.svg\", \"...   Châtelet-Les Halles  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Vérification de la table chargée\n",
    "table = bq_client.get_table(table_id)\n",
    "print(f\"[OK] - Nombre total de lignes: {table.num_rows}\")\n",
    "print(f\"[OK] - Colonnes:\")\n",
    "for field in table.schema:\n",
    "    print(f\"  - {field.name}: {field.field_type}\")\n",
    "\n",
    "# Requête simple pour vérifier les données et convertir en DataFrame pandas\n",
    "query = f\"SELECT * FROM `{table_id}` LIMIT 5\"\n",
    "results = bq_client.query(query).result()\n",
    "df = results.to_dataframe()\n",
    "\n",
    "print(f\"\\n[OK] - Aperçu des données (5 premières lignes):\")\n",
    "display(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd2937e",
   "metadata": {},
   "source": [
    "### 2.3 - Table `dim_ligne` (Référentiel des Lignes)\n",
    "\n",
    "Cette table contient les informations sur toutes les lignes de transport en commun d'Île-de-France.\n",
    "\n",
    "**Caractéristiques :**\n",
    "- **Format source** : Parquet (depuis GCS)\n",
    "- **Schéma** : Auto-détecté par BigQuery\n",
    "- **Contenu** : Informations sur les lignes (numéros, noms, types de transport, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ddd796e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[...] - Chargement de gs://bronze-sncf-etl-idfm-reims/bronze/referentiel-des-lignes/referentiel-des-lignes.parquet vers idfm-etl-reims-0224dy2025dy.silver.dim_ligne...\n",
      "[OK] - 2120 lignes chargées dans idfm-etl-reims-0224dy2025dy.silver.dim_ligne\n",
      "[OK] - Taille: 0.56 MB\n"
     ]
    }
   ],
   "source": [
    "gcs_path_lignes = \"bronze/referentiel-des-lignes/referentiel-des-lignes.parquet\"\n",
    "table_id_lignes = load_parquet_from_gcs(\n",
    "    gcs_path=gcs_path_lignes,\n",
    "    table_name=\"dim_ligne\",\n",
    "    bq_client=bq_client,\n",
    "    project_id=PROJECT_ID,\n",
    "    dataset_id=DATASET_ID,\n",
    "    bucket_name=BUCKET_NAME,\n",
    "    schema=None,  # Autodetect\n",
    "    primary_key=None\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974a769c",
   "metadata": {},
   "source": [
    "### 2.4 - Table `dim_arret` (Référentiel des Arrêts)\n",
    "\n",
    "Cette table contient les informations sur tous les arrêts de transport en commun d'Île-de-France.\n",
    "\n",
    "**Caractéristiques :**\n",
    "- **Format source** : Parquet (depuis GCS)\n",
    "- **Schéma** : Auto-détecté par BigQuery\n",
    "- **Contenu** : Informations sur les arrêts (noms, coordonnées, lignes desservies, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2e16ead6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[...] - Chargement de gs://bronze-sncf-etl-idfm-reims/bronze/arrets/arrets.parquet vers idfm-etl-reims-0224dy2025dy.silver.dim_arret...\n",
      "[OK] - 38333 lignes chargées dans idfm-etl-reims-0224dy2025dy.silver.dim_arret\n",
      "[OK] - Taille: 6.29 MB\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "gcs_path_arrets = \"bronze/arrets/arrets.parquet\"\n",
    "table_id_arrets = load_parquet_from_gcs(\n",
    "    gcs_path=gcs_path_arrets,\n",
    "    table_name=\"dim_arret\",\n",
    "    bq_client=bq_client,\n",
    "    project_id=PROJECT_ID,\n",
    "    dataset_id=DATASET_ID,\n",
    "    bucket_name=BUCKET_NAME,\n",
    "    schema=None,  # Autodetect\n",
    "    primary_key=None\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d3adda",
   "metadata": {},
   "source": [
    "### 2.5 - Table `dim_transporteur` (Liste des Transporteurs)\n",
    "\n",
    "Cette table contient les informations sur tous les transporteurs (opérateurs de transport) d'Île-de-France.\n",
    "\n",
    "**Caractéristiques :**\n",
    "- **Format source** : Parquet (depuis GCS)\n",
    "- **Schéma** : Auto-détecté par BigQuery\n",
    "- **Contenu** : Informations sur les transporteurs (noms, codes, types de transport, etc.)\n",
    "\n",
    "**Note** : Cette table de dimension permet d'identifier les différents opérateurs de transport qui gèrent les lignes et arrêts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9e9e46fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[...] - Chargement de gs://bronze-sncf-etl-idfm-reims/bronze/liste-transporteurs/liste-transporteurs.parquet vers idfm-etl-reims-0224dy2025dy.silver.dim_transporteur...\n",
      "[OK] - 53 lignes chargées dans idfm-etl-reims-0224dy2025dy.silver.dim_transporteur\n",
      "[OK] - Taille: 0.01 MB\n"
     ]
    }
   ],
   "source": [
    "gcs_path_transporteurs = \"bronze/liste-transporteurs/liste-transporteurs.parquet\"\n",
    "table_id_transporteurs = load_parquet_from_gcs(\n",
    "    gcs_path=gcs_path_transporteurs,\n",
    "    table_name=\"dim_transporteur\",\n",
    "    bq_client=bq_client,\n",
    "    project_id=PROJECT_ID,\n",
    "    dataset_id=DATASET_ID,\n",
    "    bucket_name=BUCKET_NAME,\n",
    "    schema=None,  # Autodetect\n",
    "    primary_key=None\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e9d463",
   "metadata": {},
   "source": [
    "### 2.5 - Table `dim_vacances_scolaires` (Calendrier des Vacances Scolaires)\n",
    "\n",
    "Cette table contient les périodes de vacances scolaires pour différentes zones et années.\n",
    "\n",
    "**Caractéristiques :**\n",
    "- **Format source** : CSV (depuis GCS)\n",
    "- **Schéma** : Auto-détecté par BigQuery\n",
    "- **Encodage** : UTF-8\n",
    "- **Séparateur** : Point-virgule (`;`)\n",
    "- **Contenu** : Dates de début/fin de vacances, zones, années, etc.\n",
    "\n",
    "**Note** : Pour les fichiers CSV, il est important de spécifier l'encodage et le séparateur pour éviter les erreurs de parsing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f58b4660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[...] - Chargement de gs://bronze-sncf-etl-idfm-reims/bronze/vacances-scolaires/vacances_scolaires.csv vers idfm-etl-reims-0224dy2025dy.silver.dim_vacances_scolaires...\n",
      "[OK] - 2306 lignes chargées dans idfm-etl-reims-0224dy2025dy.silver.dim_vacances_scolaires\n",
      "[OK] - Taille: 0.16 MB\n"
     ]
    }
   ],
   "source": [
    "gcs_path_vacances = \"bronze/vacances-scolaires/vacances_scolaires.csv\"\n",
    "table_id_vacances = load_csv_from_gcs(\n",
    "    gcs_path=gcs_path_vacances,\n",
    "    table_name=\"dim_vacances_scolaires\",\n",
    "    bq_client=bq_client,\n",
    "    project_id=PROJECT_ID,\n",
    "    dataset_id=DATASET_ID,\n",
    "    bucket_name=BUCKET_NAME,\n",
    "    schema=None,  # Autodetect\n",
    "    skip_leading_rows=1,\n",
    "    encoding=\"utf-8\",\n",
    "    sep=\";\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4e9487",
   "metadata": {},
   "source": [
    "## 3 - Chargement des Tables de Fait\n",
    "\n",
    "Les tables de fait contiennent les mesures et événements métier. Ici, nous chargeons les données historiques de validations des titres de transport.\n",
    "\n",
    "---\n",
    "\n",
    "### 3.1 - Configuration pour les Fichiers de Validation\n",
    "\n",
    "Les fichiers de validation historiques ont des formats différents selon les années :\n",
    "- **Encodages variés** : UTF-8, UTF-16LE, Latin-1\n",
    "- **Séparateurs variés** : Tabulation (`\\t`), point-virgule (`;`)\n",
    "- **Extensions variées** : `.txt`, `.csv`\n",
    "\n",
    "Ce dictionnaire de configuration permet de spécifier les paramètres corrects pour chaque fichier.\n",
    "\n",
    "**Note importante** : Le fichier `2023_S2_NB_FER.txt` utilise l'encodage UTF-16LE, qui n'est pas supporté directement par BigQuery. La fonction `load_csv_from_gcs` convertit automatiquement ce fichier en UTF-8 avant le chargement.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466d04b8",
   "metadata": {},
   "source": [
    "### 3.2 - Chargement des Fichiers de Validation\n",
    "\n",
    "Cette section charge tous les fichiers de validation historiques depuis GCS vers BigQuery.\n",
    "\n",
    "**Processus :**\n",
    "1. Parcourt le dictionnaire de configuration\n",
    "2. Recherche chaque fichier dans GCS\n",
    "3. Charge le fichier avec les paramètres appropriés (encodage, séparateur, format de date)\n",
    "4. Crée une table séparée pour chaque fichier (ex: `fact_validations_2015s1_nb_fer_csv`)\n",
    "\n",
    "**Gestion spéciale :**\n",
    "- **Fichiers UTF-16LE** : Conversion automatique en UTF-8 (nécessite `storage_client`)\n",
    "- **Format de date** : `DD/MM/YYYY` (format BigQuery pour les dates françaises)\n",
    "- **Schéma** : Auto-détecté (toutes les colonnes en STRING pour éviter les erreurs de parsing)\n",
    "\n",
    "**Durée estimée** : Plusieurs minutes selon le nombre et la taille des fichiers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e4c38873",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_rf_config = {\n",
    "    \"2015S1_NB_FER.csv\": {\n",
    "        \"encoding\": \"utf-8\",\n",
    "        \"sep\": \";\",\n",
    "        \"skip_rows\": 1\n",
    "    },\n",
    "    \"2015S2_NB_FER.csv\": {\n",
    "        \"encoding\": \"utf-8\",\n",
    "        \"sep\": \";\",\n",
    "        \"skip_rows\": 1\n",
    "    },\n",
    "    \"2016S1_NB_FER.txt\": {\n",
    "        \"encoding\": \"utf-8\",\n",
    "        \"sep\": \"\\t\",\n",
    "        \"skip_rows\": 1\n",
    "    },\n",
    "    \"2016S2_NB_FER.txt\": {\n",
    "        \"encoding\": \"utf-8\",\n",
    "        \"sep\": \"\\t\",\n",
    "        \"skip_rows\": 1\n",
    "    },\n",
    "    \"2017S1_NB_FER.txt\": {\n",
    "        \"encoding\": \"utf-8\",\n",
    "        \"sep\": \"\\t\",\n",
    "        \"skip_rows\": 1\n",
    "    },\n",
    "    \"2017_S2_NB_FER.txt\": {\n",
    "        \"encoding\": \"utf-8\",\n",
    "        \"sep\": \"\\t\",\n",
    "        \"skip_rows\": 1\n",
    "    },\n",
    "    \"2018_S1_NB_FER.txt\": {\n",
    "        \"encoding\": \"utf-8\",\n",
    "        \"sep\": \"\\t\",\n",
    "        \"skip_rows\": 1\n",
    "    },\n",
    "    \"2019_S1_NB_FER.txt\": {\n",
    "        \"encoding\": \"utf-8\",\n",
    "        \"sep\": \"\\t\",\n",
    "        \"skip_rows\": 1\n",
    "    },\n",
    "    \"2019_S2_NB_FER.txt\": {\n",
    "        \"encoding\": \"utf-8\",\n",
    "        \"sep\": \"\\t\",\n",
    "        \"skip_rows\": 1\n",
    "    },\n",
    "    \"2020_S1_NB_FER.txt\": {\n",
    "        \"encoding\": \"utf-8\",\n",
    "        \"sep\": \"\\t\",\n",
    "        \"skip_rows\": 1\n",
    "    },\n",
    "    \"2020_S2_NB_FER.txt\": {\n",
    "        \"encoding\": \"utf-8\",\n",
    "        \"sep\": \"\\t\",\n",
    "        \"skip_rows\": 1\n",
    "    },\n",
    "    \"2021_S1_NB_FER.txt\": {\n",
    "        \"encoding\": \"utf-8\",\n",
    "        \"sep\": \"\\t\",\n",
    "        \"skip_rows\": 1\n",
    "    },\n",
    "    \"2021_S2_NB_FER.txt\": {\n",
    "        \"encoding\": \"utf-8\",\n",
    "        \"sep\": \"\\t\",\n",
    "        \"skip_rows\": 1\n",
    "    },\n",
    "    \"2022_S1_NB_FER.txt\": {\n",
    "        \"encoding\": \"utf-8\",\n",
    "        \"sep\": \"\\t\",\n",
    "        \"skip_rows\": 1\n",
    "    },\n",
    "    \"2022_S2_NB_FER.txt\": {\n",
    "        \"encoding\": \"utf-8\",\n",
    "        \"sep\": \";\",\n",
    "        \"skip_rows\": 1\n",
    "    },\n",
    "    \"2023_S2_NB_FER.txt\": {\n",
    "        \"encoding\": \"utf-16le\",\n",
    "        \"sep\": \"\\t\",\n",
    "        \"skip_rows\": 1\n",
    "    },\n",
    "    \"2024_S1_NB_FER.txt\": {\n",
    "        \"encoding\": \"utf-8\",\n",
    "        \"sep\": \"\\t\",\n",
    "        \"skip_rows\": 1\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "41e86c60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[...] - Chargement de gs://bronze-sncf-etl-idfm-reims/bronze/histo-validations-reseau-ferre/2015/data-rf-2015/2015S1_NB_FER.csv vers idfm-etl-reims-0224dy2025dy.silver.fact_validations_2015s1_nb_fer_csv...\n",
      "[OK] - 755989 lignes chargées dans idfm-etl-reims-0224dy2025dy.silver.fact_validations_2015s1_nb_fer_csv\n",
      "[OK] - Taille: 45.93 MB\n",
      "\n",
      "[...] - Chargement de gs://bronze-sncf-etl-idfm-reims/bronze/histo-validations-reseau-ferre/2015/data-rf-2015/2015S2_NB_FER.csv vers idfm-etl-reims-0224dy2025dy.silver.fact_validations_2015s2_nb_fer_csv...\n",
      "[OK] - 778747 lignes chargées dans idfm-etl-reims-0224dy2025dy.silver.fact_validations_2015s2_nb_fer_csv\n",
      "[OK] - Taille: 47.28 MB\n",
      "\n",
      "[...] - Chargement de gs://bronze-sncf-etl-idfm-reims/bronze/histo-validations-reseau-ferre/2016/data-rf-2016/2016S1_NB_FER.txt vers idfm-etl-reims-0224dy2025dy.silver.fact_validations_2016s1_nb_fer_txt...\n",
      "[OK] - 779712 lignes chargées dans idfm-etl-reims-0224dy2025dy.silver.fact_validations_2016s1_nb_fer_txt\n",
      "[OK] - Taille: 52.96 MB\n",
      "\n",
      "[...] - Chargement de gs://bronze-sncf-etl-idfm-reims/bronze/histo-validations-reseau-ferre/2016/data-rf-2016/2016S2_NB_FER.txt vers idfm-etl-reims-0224dy2025dy.silver.fact_validations_2016s2_nb_fer_txt...\n",
      "[OK] - 774421 lignes chargées dans idfm-etl-reims-0224dy2025dy.silver.fact_validations_2016s2_nb_fer_txt\n",
      "[OK] - Taille: 52.59 MB\n",
      "\n",
      "[...] - Chargement de gs://bronze-sncf-etl-idfm-reims/bronze/histo-validations-reseau-ferre/2017/data-rf-2017/2017S1_NB_FER.txt vers idfm-etl-reims-0224dy2025dy.silver.fact_validations_2017s1_nb_fer_txt...\n",
      "[OK] - 780270 lignes chargées dans idfm-etl-reims-0224dy2025dy.silver.fact_validations_2017s1_nb_fer_txt\n",
      "[OK] - Taille: 53.02 MB\n",
      "\n",
      "[...] - Chargement de gs://bronze-sncf-etl-idfm-reims/bronze/histo-validations-reseau-ferre/2017/data-rf-2017/2017_S2_NB_FER.txt vers idfm-etl-reims-0224dy2025dy.silver.fact_validations_2017_s2_nb_fer_txt...\n",
      "[OK] - 825698 lignes chargées dans idfm-etl-reims-0224dy2025dy.silver.fact_validations_2017_s2_nb_fer_txt\n",
      "[OK] - Taille: 52.00 MB\n",
      "\n",
      "[...] - Chargement de gs://bronze-sncf-etl-idfm-reims/bronze/histo-validations-reseau-ferre/2018/data-rf-2018/2018_S1_NB_FER.txt vers idfm-etl-reims-0224dy2025dy.silver.fact_validations_2018_s1_nb_fer_txt...\n",
      "[OK] - 866694 lignes chargées dans idfm-etl-reims-0224dy2025dy.silver.fact_validations_2018_s1_nb_fer_txt\n",
      "[OK] - Taille: 54.94 MB\n",
      "\n",
      "[...] - Chargement de gs://bronze-sncf-etl-idfm-reims/bronze/histo-validations-reseau-ferre/2019/data-rf-2019/2019_S1_NB_FER.txt vers idfm-etl-reims-0224dy2025dy.silver.fact_validations_2019_s1_nb_fer_txt...\n",
      "[OK] - 934851 lignes chargées dans idfm-etl-reims-0224dy2025dy.silver.fact_validations_2019_s1_nb_fer_txt\n",
      "[OK] - Taille: 59.47 MB\n",
      "\n",
      "[...] - Chargement de gs://bronze-sncf-etl-idfm-reims/bronze/histo-validations-reseau-ferre/2019/data-rf-2019/2019_S2_NB_FER.txt vers idfm-etl-reims-0224dy2025dy.silver.fact_validations_2019_s2_nb_fer_txt...\n",
      "[OK] - 953454 lignes chargées dans idfm-etl-reims-0224dy2025dy.silver.fact_validations_2019_s2_nb_fer_txt\n",
      "[OK] - Taille: 60.98 MB\n",
      "\n",
      "[...] - Chargement de gs://bronze-sncf-etl-idfm-reims/bronze/histo-validations-reseau-ferre/2020/data-rf-2020/2020_S1_NB_FER.txt vers idfm-etl-reims-0224dy2025dy.silver.fact_validations_2020_s1_nb_fer_txt...\n",
      "[OK] - 887493 lignes chargées dans idfm-etl-reims-0224dy2025dy.silver.fact_validations_2020_s1_nb_fer_txt\n",
      "[OK] - Taille: 56.89 MB\n",
      "\n",
      "[...] - Chargement de gs://bronze-sncf-etl-idfm-reims/bronze/histo-validations-reseau-ferre/2020/data-rf-2020/2020_S2_NB_FER.txt vers idfm-etl-reims-0224dy2025dy.silver.fact_validations_2020_s2_nb_fer_txt...\n",
      "[OK] - 1054012 lignes chargées dans idfm-etl-reims-0224dy2025dy.silver.fact_validations_2020_s2_nb_fer_txt\n",
      "[OK] - Taille: 67.52 MB\n",
      "\n",
      "[...] - Chargement de gs://bronze-sncf-etl-idfm-reims/bronze/histo-validations-reseau-ferre/2021/data-rf-2021/2021_S1_NB_FER.txt vers idfm-etl-reims-0224dy2025dy.silver.fact_validations_2021_s1_nb_fer_txt...\n",
      "[OK] - 1064019 lignes chargées dans idfm-etl-reims-0224dy2025dy.silver.fact_validations_2021_s1_nb_fer_txt\n",
      "[OK] - Taille: 68.20 MB\n",
      "\n",
      "[...] - Chargement de gs://bronze-sncf-etl-idfm-reims/bronze/histo-validations-reseau-ferre/2021/data-rf-2021/2021_S2_NB_FER.txt vers idfm-etl-reims-0224dy2025dy.silver.fact_validations_2021_s2_nb_fer_txt...\n",
      "[OK] - 1084281 lignes chargées dans idfm-etl-reims-0224dy2025dy.silver.fact_validations_2021_s2_nb_fer_txt\n",
      "[OK] - Taille: 69.54 MB\n",
      "\n",
      "[...] - Chargement de gs://bronze-sncf-etl-idfm-reims/bronze/histo-validations-reseau-ferre/2022/data-rf-2022/2022_S1_NB_FER.txt vers idfm-etl-reims-0224dy2025dy.silver.fact_validations_2022_s1_nb_fer_txt...\n",
      "[OK] - 1088334 lignes chargées dans idfm-etl-reims-0224dy2025dy.silver.fact_validations_2022_s1_nb_fer_txt\n",
      "[OK] - Taille: 69.80 MB\n",
      "\n",
      "[...] - Chargement de gs://bronze-sncf-etl-idfm-reims/bronze/histo-validations-reseau-ferre/2022/data-rf-2022/2022_S2_NB_FER.txt vers idfm-etl-reims-0224dy2025dy.silver.fact_validations_2022_s2_nb_fer_txt...\n",
      "[OK] - 1105947 lignes chargées dans idfm-etl-reims-0224dy2025dy.silver.fact_validations_2022_s2_nb_fer_txt\n",
      "[OK] - Taille: 69.08 MB\n",
      "\n",
      "[...] - Conversion UTF-16LE -> UTF-8 pour bronze/histo-validations-reseau-ferre/2023/data-rf-2023/2023_S2_NB_FER.txt...\n",
      "[OK] - Fichier converti et uploadé vers bronze/histo-validations-reseau-ferre/2023/data-rf-2023/2023_S2_NB_FER.txt.utf8\n",
      "\n",
      "[...] - Chargement de gs://bronze-sncf-etl-idfm-reims/bronze/histo-validations-reseau-ferre/2023/data-rf-2023/2023_S2_NB_FER.txt.utf8 vers idfm-etl-reims-0224dy2025dy.silver.fact_validations_2023_s2_nb_fer_txt...\n",
      "[OK] - 849596 lignes chargées dans idfm-etl-reims-0224dy2025dy.silver.fact_validations_2023_s2_nb_fer_txt\n",
      "[OK] - Taille: 62.86 MB\n",
      "[OK] - Fichier temporaire bronze/histo-validations-reseau-ferre/2023/data-rf-2023/2023_S2_NB_FER.txt.utf8 supprimé\n",
      "\n",
      "[...] - Chargement de gs://bronze-sncf-etl-idfm-reims/bronze/histo-validations-reseau-ferre/2024/data-rf-2024/2024_S1_NB_FER.txt vers idfm-etl-reims-0224dy2025dy.silver.fact_validations_2024_s1_nb_fer_txt...\n",
      "[OK] - 859043 lignes chargées dans idfm-etl-reims-0224dy2025dy.silver.fact_validations_2024_s1_nb_fer_txt\n",
      "[OK] - Taille: 63.60 MB\n"
     ]
    }
   ],
   "source": [
    "# Charger tous les fichiers de validation depuis GCS vers BigQuery\n",
    "bucket = storage_client.bucket(BUCKET_NAME)\n",
    "\n",
    "# Parcourir tous les fichiers dans la configuration\n",
    "for filename, config in load_rf_config.items():\n",
    "    # Chercher le fichier dans GCS\n",
    "    blobs = list(bucket.list_blobs(prefix=\"bronze/histo-validations-reseau-ferre/\"))\n",
    "    \n",
    "    # Trouver le blob correspondant\n",
    "    blob = None\n",
    "    for b in blobs:\n",
    "        if b.name.endswith(filename):\n",
    "            blob = b\n",
    "            break\n",
    "    \n",
    "    if blob is None:\n",
    "        print(f\"[SKIP] - {filename} (non trouvé dans GCS)\")\n",
    "        continue\n",
    "    \n",
    "    gcs_path = blob.name\n",
    "    table_name = f\"fact_validations_{filename.replace('.', '_').replace('-', '_').lower()}\"\n",
    "    \n",
    "    sep = config[\"sep\"]\n",
    "    encoding = config[\"encoding\"]\n",
    "    \n",
    "    # Convertir \"\\t\" en tabulation réelle si nécessaire\n",
    "    if sep == \"\\\\t\":\n",
    "        sep = \"\\t\"\n",
    "    \n",
    "    # Utiliser la fonction load_csv_from_gcs avec le schéma unifié (toutes les colonnes en STRING)\n",
    "    table_id = load_csv_from_gcs(\n",
    "        gcs_path=gcs_path,\n",
    "        table_name=table_name,\n",
    "        bq_client=bq_client,\n",
    "        project_id=PROJECT_ID,\n",
    "        dataset_id=DATASET_ID,\n",
    "        bucket_name=BUCKET_NAME,\n",
    "        schema=None,\n",
    "        skip_leading_rows=config.get(\"skip_rows\", 1),\n",
    "        encoding=encoding,\n",
    "        sep=sep,\n",
    "        date_format=\"DD/MM/YYYY\",  # Format BigQuery pour les dates\n",
    "        storage_client=storage_client,  # Requis pour la conversion UTF-16LE\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
