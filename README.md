# Pipeline ETL Big Data - SNCF GCP

Pipeline ETL pour l'analyse des donn√©es de transport en commun d'√éle-de-France sur Google Cloud Platform.

## Structure du Projet

```
m2-univ-reims-sep-cs-etl-sncf-gcp/
‚îú‚îÄ‚îÄ notebooks/
‚îÇ   ‚îú‚îÄ‚îÄ 0_test_connection.ipynb          # Test de connexion GCS/BigQuery
‚îÇ   ‚îú‚îÄ‚îÄ 1_[EXTRACT]_ingest_to_gcs.ipynb    # Extraction et ingestion vers GCS (bronze)
‚îÇ   ‚îú‚îÄ‚îÄ 2_[LOAD]_load_to_bigquery.ipynb    # Chargement vers BigQuery (silver)
‚îÇ   ‚îî‚îÄ‚îÄ 3_[TRANSFORM]_analyze_for_gold.ipynb  # Analyse pour la couche gold
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ gcs_utils.py                       # Utilitaires GCS
‚îÇ   ‚îî‚îÄ‚îÄ bq_utils.py                        # Utilitaires BigQuery
‚îú‚îÄ‚îÄ data/                                  # Donn√©es locales (temporaires)
‚îú‚îÄ‚îÄ secrets/                               # Credentials GCP
‚îî‚îÄ‚îÄ requirements.txt                       # D√©pendances Python
```

## Architecture du Pipeline

Le pipeline suit une architecture en **3 couches** (Medallion Architecture) :

1. **Bronze** (GCS) : Donn√©es brutes, non transform√©es
2. **Silver** (BigQuery) : Donn√©es brutes charg√©es sur BigQuery
3. **Gold** (BigQuery) : Donn√©es Nettoy√©es et agr√©g√©es et optimis√©es pour l'analyse m√©tier

## üîó Liens vers les Sources de Donn√©es

### √éle-de-France Mobilit√©s
- **Portail Open Data** : https://data.iledefrance-mobilites.fr/
- **API Documentation** : https://data.iledefrance-mobilites.fr/api/explore/v2.1/catalog/
- **Datasets utilis√©s** :
  - [Emplacement des gares](https://data.iledefrance-mobilites.fr/explore/dataset/emplacement-des-gares-idf/)
  - [R√©f√©rentiel des lignes](https://data.iledefrance-mobilites.fr/explore/dataset/referentiel-des-lignes/)
  - [Arr√™ts](https://data.iledefrance-mobilites.fr/explore/dataset/arrets/)
  - [Liste des transporteurs](https://data.iledefrance-mobilites.fr/explore/dataset/liste-transporteurs/)
  - [Validations historiques r√©seau ferr√©](https://data.iledefrance-mobilites.fr/explore/dataset/histo-validations-reseau-ferre/)

### Minist√®re de l'√âducation Nationale
- **Portail Open Data** : https://data.education.gouv.fr/
- **Dataset** : [Calendrier scolaire](https://data.education.gouv.fr/explore/dataset/fr-en-calendrier-scolaire/)

### API Calendrier Gouv
- **Documentation** : https://calendrier.api.gouv.fr/
- **Endpoint Jours F√©ri√©s** : https://calendrier.api.gouv.fr/jours-feries/

### Open-Meteo
- **Documentation** : https://open-meteo.com/en/docs
- **API Historique** : https://open-meteo.com/en/docs/historical-weather-api

### GeoAPI
- **Documentation** : https://geo.api.gouv.fr/
- **API Communes** : https://geo.api.gouv.fr/communes

## D√©marrage Rapide

### Pr√©requis

1. **Compte Google Cloud Platform** avec un projet cr√©√©
2. **Service Account** avec les permissions n√©cessaires
3. **Bucket GCS** cr√©√©
4. **Python 3.11+** avec les packages install√©s

### Installation

```bash
# Cloner le repository
git clone https://github.com/ettouilebouael/m2-univ-reims-sep-cs-etl-sncf-gcp
cd m2-univ-reims-sep-cs-etl-sncf-gcp

# Cr√©er un environnement virtuel
python -m venv venv

# Activer l'environnement virtuel
# Sur macOS/Linux :
source venv/bin/activate
# Sur Windows :
# venv\Scripts\activate

# Installer les d√©pendances
pip install -r requirements.txt
```

### Configuration

Cr√©er un fichier `.env` √† la racine du projet :

```env
PROJECT_ID=your-gcp-project-id
GOOGLE_APPLICATION_CREDENTIALS=secrets/your-service-account.json
BUCKET_NAME=your-gcs-bucket-name
```

### Ex√©cution des Notebooks

1. **Notebook 0** : Tester la connexion √† GCS et BigQuery
2. **Notebook 1** : Extraire et ing√©rer les donn√©es vers GCS (bronze)
3. **Notebook 2** : Charger les donn√©es vers BigQuery (silver)
4. **Notebook 3** : Analyser les donn√©es pour pr√©parer la couche gold

## Documentation des Notebooks

- **`0_test_connection.ipynb`** : V√©rification de la configuration et des connexions
- **`1_[EXTRACT]_ingest_to_gcs.ipynb`** : Extraction depuis les APIs publiques et ingestion vers GCS
- **`2_[LOAD]_load_to_bigquery.ipynb`** : Chargement des donn√©es depuis GCS vers BigQuery avec sch√©ma en √©toile
- **`3_[TRANSFORM]_analyze_for_gold.ipynb`** : Analyse des donn√©es pour identifier les transformations n√©cessaires √† la couche gold

## Technologies Utilis√©es
- **Google Cloud Python SDK** : Interaction avec les services GCP
- **Google Cloud Storage (GCS)** : Stockage des donn√©es brutes
- **BigQuery** : Data warehouse pour l'analyse
- **Python** : Langage de programmation
- **Pandas** : Manipulation de donn√©es (inspection locale uniquement)


## Licence

Ce projet est destin√© √† un usage p√©dagogique dans le cadre du Master 2 de l'Universit√© de Reims.

## Auteurs

Projet r√©alis√© dans le cadre du Master 2 - Universit√© de Reims Champagne-Ardenne.
