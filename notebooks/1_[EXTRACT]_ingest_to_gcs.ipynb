{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3643f03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "from zipfile import ZipFile\n",
    "from google.cloud import storage\n",
    "from google.oauth2 import service_account\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "ROOT = Path.cwd().parent\n",
    "DATA_DIR = ROOT / \"data\"\n",
    "DATA_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "PROJECT_ID = os.getenv(\"PROJECT_ID\")\n",
    "SA_PATH = ROOT / os.getenv(\"GOOGLE_APPLICATION_CREDENTIALS\")\n",
    "BUCKET_NAME = os.getenv(\"BUCKET_NAME\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ec8de4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authentification Google Cloud\n",
    "creds = service_account.Credentials.from_service_account_file(SA_PATH)\n",
    "storage_client = storage.Client(project=PROJECT_ID, credentials=creds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8e0003e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utils functions\n",
    "def download_parquet_from_idfm(dataset_name):\n",
    "    \"\"\"Télécharge un fichier Parquet depuis l'API IDFM\"\"\"\n",
    "    URL = f\"https://data.iledefrance-mobilites.fr/api/explore/v2.1/catalog/datasets/{dataset_name}/exports/parquet?parquet_compression=snappy\"\n",
    "    OUTPUT_FILE = f\"{dataset_name}.parquet\"\n",
    "\n",
    "    dataset_dir = DATA_DIR / dataset_name\n",
    "    dataset_dir.mkdir(exist_ok=True)\n",
    "    parquet_path = dataset_dir / OUTPUT_FILE\n",
    "\n",
    "    print(f\"[...] - Téléchargement du fichier Parquet {dataset_name}...\")\n",
    "\n",
    "    response = requests.get(URL, timeout=300)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    parquet_path.write_bytes(response.content)\n",
    "\n",
    "    file_size_mb = parquet_path.stat().st_size / (1024 * 1024)\n",
    "    print(f\"[OK] - Téléchargé: {parquet_path}\")\n",
    "    print(f\"[OK] - Taille: {file_size_mb:.2f} MB\")\n",
    "    \n",
    "    return parquet_path\n",
    "\n",
    "def upload_to_gcs(file_path, gcs_folder=\"bronze\", gcs_subfolder=\"\"):\n",
    "    \"\"\"Upload un fichier local vers Google Cloud Storage\"\"\"\n",
    "    file_path = Path(file_path)\n",
    "    \n",
    "    if not file_path.exists():\n",
    "        raise FileNotFoundError(f\"Le fichier {file_path} n'existe pas\")\n",
    "    \n",
    "    bucket = storage_client.bucket(BUCKET_NAME)\n",
    "    gcs_path = f\"{gcs_folder}/{gcs_subfolder}/{file_path.name}\" if gcs_subfolder else f\"{gcs_folder}/{file_path.name}\"\n",
    "    blob = bucket.blob(gcs_path)\n",
    "    \n",
    "    print(f\"[...] - Upload de {file_path.name} vers GCS...\")\n",
    "    blob.upload_from_filename(str(file_path))\n",
    "    \n",
    "    file_size_mb = file_path.stat().st_size / (1024 * 1024)\n",
    "    print(f\"[OK] - Uploadé: gs://{BUCKET_NAME}/{gcs_path}\")\n",
    "    print(f\"[OK] - Taille: {file_size_mb:.2f} MB\")\n",
    "    \n",
    "    return f\"gs://{BUCKET_NAME}/{gcs_path}\"\n",
    "\n",
    "def upload_folder_to_gcs(folder_path, gcs_folder=\"bronze\", gcs_subfolder=\"\", extensions=None):\n",
    "    \"\"\"Upload récursivement tous les fichiers d'un dossier vers GCS en préservant la structure\n",
    "    \n",
    "    Args:\n",
    "        folder_path: Chemin du dossier local à uploader\n",
    "        gcs_folder: Dossier de base dans GCS (défaut: \"bronze\")\n",
    "        gcs_subfolder: Sous-dossier dans GCS (défaut: \"\")\n",
    "        extensions: Liste des extensions à uploader (ex: [\".csv\", \".txt\"]). Si None, upload tous les fichiers\n",
    "    \"\"\"\n",
    "    folder_path = Path(folder_path)\n",
    "    \n",
    "    if not folder_path.exists():\n",
    "        raise FileNotFoundError(f\"Le dossier {folder_path} n'existe pas\")\n",
    "    \n",
    "    # Normaliser les extensions (ajouter le point si absent, mettre en minuscule)\n",
    "    if extensions:\n",
    "        extensions = [ext.lower() if ext.startswith(\".\") else f\".{ext.lower()}\" for ext in extensions]\n",
    "    \n",
    "    bucket = storage_client.bucket(BUCKET_NAME)\n",
    "    uploaded_files = 0\n",
    "    total_size = 0\n",
    "    skipped_files = 0\n",
    "    \n",
    "    print(f\"[...] - Upload du dossier {folder_path.name} vers GCS...\")\n",
    "    if extensions:\n",
    "        print(f\"[...] - Extensions filtrées: {', '.join(extensions)}\")\n",
    "    \n",
    "    # Parcourir récursivement tous les fichiers\n",
    "    for file_path in folder_path.rglob(\"*\"):\n",
    "        if file_path.is_file():\n",
    "            # Filtrer par extension si spécifié\n",
    "            if extensions and file_path.suffix.lower() not in extensions:\n",
    "                skipped_files += 1\n",
    "                continue\n",
    "            \n",
    "            # Calculer le chemin relatif depuis le dossier source\n",
    "            relative_path = file_path.relative_to(folder_path)\n",
    "            \n",
    "            # Construire le chemin GCS en préservant la structure\n",
    "            if gcs_subfolder:\n",
    "                gcs_path = f\"{gcs_folder}/{gcs_subfolder}/{relative_path.as_posix()}\"\n",
    "            else:\n",
    "                gcs_path = f\"{gcs_folder}/{relative_path.as_posix()}\"\n",
    "            \n",
    "            blob = bucket.blob(gcs_path)\n",
    "            blob.upload_from_filename(str(file_path))\n",
    "            \n",
    "            file_size = file_path.stat().st_size\n",
    "            total_size += file_size\n",
    "            uploaded_files += 1\n",
    "            \n",
    "            print(f\"  ✓ {relative_path.as_posix()}\")\n",
    "    \n",
    "    total_size_mb = total_size / (1024 * 1024)\n",
    "    print(f\"[OK] - {uploaded_files} fichiers uploadés\")\n",
    "    if skipped_files > 0:\n",
    "        print(f\"[OK] - {skipped_files} fichiers ignorés (extension non autorisée)\")\n",
    "    print(f\"[OK] - Taille totale: {total_size_mb:.2f} MB\")\n",
    "    print(f\"[OK] - Dossier GCS: gs://{BUCKET_NAME}/{gcs_folder}/{gcs_subfolder if gcs_subfolder else folder_path.name}/\")\n",
    "    \n",
    "    return uploaded_files\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e5382f",
   "metadata": {},
   "source": [
    "# 1 - Ingestion des données historiques de validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d7ade6eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de fichiers trouvés: 10\n",
      "\n",
      "Fichiers disponibles:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annee</th>\n",
       "      <th>filename</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017</td>\n",
       "      <td>data-rf-2017.zip</td>\n",
       "      <td>https://data.iledefrance-mobilites.fr/api/expl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019</td>\n",
       "      <td>data-rf-2019.zip</td>\n",
       "      <td>https://data.iledefrance-mobilites.fr/api/expl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020</td>\n",
       "      <td>data-rf-2020.zip</td>\n",
       "      <td>https://data.iledefrance-mobilites.fr/api/expl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021</td>\n",
       "      <td>data-rf-2021.zip</td>\n",
       "      <td>https://data.iledefrance-mobilites.fr/api/expl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016</td>\n",
       "      <td>data-rf-2016.zip</td>\n",
       "      <td>https://data.iledefrance-mobilites.fr/api/expl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2018</td>\n",
       "      <td>data-rf-2018.zip</td>\n",
       "      <td>https://data.iledefrance-mobilites.fr/api/expl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2022</td>\n",
       "      <td>data-rf-2022.zip</td>\n",
       "      <td>https://data.iledefrance-mobilites.fr/api/expl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2023</td>\n",
       "      <td>data-rf-2023.zip</td>\n",
       "      <td>https://data.iledefrance-mobilites.fr/api/expl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2015</td>\n",
       "      <td>data-rf-2015.zip</td>\n",
       "      <td>https://data.iledefrance-mobilites.fr/api/expl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2024</td>\n",
       "      <td>data-rf-2024.zip</td>\n",
       "      <td>https://data.iledefrance-mobilites.fr/api/expl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   annee          filename                                                url\n",
       "0   2017  data-rf-2017.zip  https://data.iledefrance-mobilites.fr/api/expl...\n",
       "1   2019  data-rf-2019.zip  https://data.iledefrance-mobilites.fr/api/expl...\n",
       "2   2020  data-rf-2020.zip  https://data.iledefrance-mobilites.fr/api/expl...\n",
       "3   2021  data-rf-2021.zip  https://data.iledefrance-mobilites.fr/api/expl...\n",
       "4   2016  data-rf-2016.zip  https://data.iledefrance-mobilites.fr/api/expl...\n",
       "5   2018  data-rf-2018.zip  https://data.iledefrance-mobilites.fr/api/expl...\n",
       "6   2022  data-rf-2022.zip  https://data.iledefrance-mobilites.fr/api/expl...\n",
       "7   2023  data-rf-2023.zip  https://data.iledefrance-mobilites.fr/api/expl...\n",
       "8   2015  data-rf-2015.zip  https://data.iledefrance-mobilites.fr/api/expl...\n",
       "9   2024  data-rf-2024.zip  https://data.iledefrance-mobilites.fr/api/expl..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1.1 - Récupération des liens des fichiers depuis l'API ile de de France Mobilités\n",
    "URL = \"https://data.iledefrance-mobilites.fr/api/explore/v2.1/catalog/datasets/histo-validations-reseau-ferre/records\"\n",
    "\n",
    "response = requests.get(URL, timeout=60)\n",
    "response.raise_for_status()\n",
    "\n",
    "records = response.json().get(\"results\", [])\n",
    "print(f\"Nombre de fichiers trouvés: {len(records)}\")\n",
    "\n",
    "df_metadata = pd.DataFrame([\n",
    "    {\n",
    "        'annee': int(r['annee']),\n",
    "        'filename': r['reseau_ferre']['filename'],\n",
    "        'url': r['reseau_ferre']['url']\n",
    "    }\n",
    "    for r in records\n",
    "])\n",
    "\n",
    "print(\"\\nFichiers disponibles:\")\n",
    "display(df_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e6f671d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[...] - Téléchargement 2017 (data-rf-2017.zip)\n",
      "[OK] - Téléchargé\n",
      "[OK] - Extrait dans /Users/admin/Desktop/projects/m2-univ-reims-sep-cs-etl-sncf-gcp/data/histo-validations-reseau-ferre/2017\n",
      "[...] - Téléchargement 2019 (data-rf-2019.zip)\n",
      "[OK] - Téléchargé\n",
      "[OK] - Extrait dans /Users/admin/Desktop/projects/m2-univ-reims-sep-cs-etl-sncf-gcp/data/histo-validations-reseau-ferre/2019\n",
      "[...] - Téléchargement 2020 (data-rf-2020.zip)\n",
      "[OK] - Téléchargé\n",
      "[OK] - Extrait dans /Users/admin/Desktop/projects/m2-univ-reims-sep-cs-etl-sncf-gcp/data/histo-validations-reseau-ferre/2020\n",
      "[...] - Téléchargement 2021 (data-rf-2021.zip)\n",
      "[OK] - Téléchargé\n",
      "[OK] - Extrait dans /Users/admin/Desktop/projects/m2-univ-reims-sep-cs-etl-sncf-gcp/data/histo-validations-reseau-ferre/2021\n",
      "[...] - Téléchargement 2016 (data-rf-2016.zip)\n",
      "[OK] - Téléchargé\n",
      "[OK] - Extrait dans /Users/admin/Desktop/projects/m2-univ-reims-sep-cs-etl-sncf-gcp/data/histo-validations-reseau-ferre/2016\n",
      "[...] - Téléchargement 2018 (data-rf-2018.zip)\n",
      "[OK] - Téléchargé\n",
      "[OK] - Extrait dans /Users/admin/Desktop/projects/m2-univ-reims-sep-cs-etl-sncf-gcp/data/histo-validations-reseau-ferre/2018\n",
      "[...] - Téléchargement 2022 (data-rf-2022.zip)\n",
      "[OK] - Téléchargé\n",
      "[OK] - Extrait dans /Users/admin/Desktop/projects/m2-univ-reims-sep-cs-etl-sncf-gcp/data/histo-validations-reseau-ferre/2022\n",
      "[...] - Téléchargement 2023 (data-rf-2023.zip)\n",
      "[OK] - Téléchargé\n",
      "[OK] - Extrait dans /Users/admin/Desktop/projects/m2-univ-reims-sep-cs-etl-sncf-gcp/data/histo-validations-reseau-ferre/2023\n",
      "[...] - Téléchargement 2015 (data-rf-2015.zip)\n",
      "[OK] - Téléchargé\n",
      "[OK] - Extrait dans /Users/admin/Desktop/projects/m2-univ-reims-sep-cs-etl-sncf-gcp/data/histo-validations-reseau-ferre/2015\n",
      "[...] - Téléchargement 2024 (data-rf-2024.zip)\n",
      "[OK] - Téléchargé\n",
      "[OK] - Extrait dans /Users/admin/Desktop/projects/m2-univ-reims-sep-cs-etl-sncf-gcp/data/histo-validations-reseau-ferre/2024\n",
      "\n",
      "[OK] - Terminé: /Users/admin/Desktop/projects/m2-univ-reims-sep-cs-etl-sncf-gcp/data/histo-validations-reseau-ferre\n"
     ]
    }
   ],
   "source": [
    "# 1.2 - Téléchargement des fichiers\n",
    "BASE_DIR = DATA_DIR / \"histo-validations-reseau-ferre\"\n",
    "BASE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for row in df_metadata.itertuples():\n",
    "    year_dir = BASE_DIR / str(row.annee)\n",
    "    year_dir.mkdir(exist_ok=True)\n",
    "    zip_path = year_dir / row.filename\n",
    "\n",
    "    print(f\"[...] - Téléchargement {row.annee} ({row.filename})\")\n",
    "    try:\n",
    "        response = requests.get(row.url, timeout=300)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        zip_path.write_bytes(response.content)\n",
    "        print(f\"[OK] - Téléchargé\")\n",
    "        \n",
    "        with ZipFile(zip_path) as zf:\n",
    "            zf.extractall(year_dir)\n",
    "        print(f\"[OK] - Extrait dans {year_dir}\")\n",
    "        \n",
    "        zip_path.unlink()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"[Erreur] {row.annee}: {e}\")\n",
    "\n",
    "print(f\"\\n[OK] - Terminé: {BASE_DIR}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9595d6bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Upload] - Upload des données historiques vers GCS...\n",
      "[...] - Upload du dossier histo-validations-reseau-ferre vers GCS...\n",
      "[...] - Extensions filtrées: .csv, .txt\n",
      "  ✓ 2022/data-rf-2022/2022_S2_PROFIL_FER.txt\n",
      "  ✓ 2022/data-rf-2022/2022_S1_NB_FER.txt\n",
      "  ✓ 2022/data-rf-2022/2022_S1_PROFIL_FER.txt\n",
      "  ✓ 2022/data-rf-2022/2022_S2_NB_FER.txt\n",
      "  ✓ 2024/2024_S1_PROFIL_FER.txt\n",
      "  ✓ 2024/2024_S1_NB_FER.txt\n",
      "  ✓ 2023/data-rf-2023/2023_S2_PROFIL_FER.txt\n",
      "  ✓ 2023/data-rf-2023/2023_S1_NB_FER .txt\n",
      "  ✓ 2023/data-rf-2023/2023_S2_NB_FER.txt\n",
      "  ✓ 2023/data-rf-2023/2023_S1_PROFIL_FER.txt\n",
      "  ✓ 2015/data-rf-2015/2015S2_NB_FER.csv\n",
      "  ✓ 2015/data-rf-2015/2015S1_PROFIL_FER.csv\n",
      "  ✓ 2015/data-rf-2015/2015S2_PROFIL_FER.csv\n",
      "  ✓ 2015/data-rf-2015/2015S1_NB_FER.csv\n",
      "  ✓ 2017/data-rf-2017/2017_S2_PROFIL_FER.txt\n",
      "  ✓ 2017/data-rf-2017/2017_S2_NB_FER.txt\n",
      "  ✓ 2017/data-rf-2017/2017S1_PROFIL_FER.txt\n",
      "  ✓ 2017/data-rf-2017/2017S1_NB_FER.txt\n",
      "  ✓ 2019/data-rf-2019/2019_S2_NB_FER.txt\n",
      "  ✓ 2019/data-rf-2019/2019_S2_PROFIL_FER.txt\n",
      "  ✓ 2019/data-rf-2019/2019_S1_NB_FER.txt\n",
      "  ✓ 2019/data-rf-2019/2019_S1_PROFIL_FER.txt\n",
      "  ✓ 2021/data-rf-2021/2021_S1_NB_FER.txt\n",
      "  ✓ 2021/data-rf-2021/2021_S1_PROFIL_FER.txt\n",
      "  ✓ 2021/data-rf-2021/2021_S2_PROFIL_FER.txt\n",
      "  ✓ 2021/data-rf-2021/2021_S2_NB_FER.txt\n",
      "  ✓ 2020/data-rf-2020/2020_S2_NB_FER.txt\n",
      "  ✓ 2020/data-rf-2020/2020_S1_PROFIL_FER.txt\n",
      "  ✓ 2020/data-rf-2020/2020_S2_PROFIL_FER.txt\n",
      "  ✓ 2020/data-rf-2020/2020_S1_NB_FER.txt\n",
      "  ✓ 2018/data-rf-2018/2018_S1_NB_FER.txt\n",
      "  ✓ 2018/data-rf-2018/2018_S2_Profil_Fer.txt\n",
      "  ✓ 2018/data-rf-2018/2018_S1_PROFIL_FER.txt\n",
      "  ✓ 2018/data-rf-2018/2018_S2_NB_Fer.txt\n",
      "  ✓ 2016/data-rf-2016/2016S2_NB_FER.txt\n",
      "  ✓ 2016/data-rf-2016/2016S2_PROFIL_FER.txt\n",
      "  ✓ 2016/data-rf-2016/2016S1_NB_FER.txt\n",
      "  ✓ 2016/data-rf-2016/2016S1_PROFIL_FER.txt\n",
      "[OK] - 38 fichiers uploadés\n",
      "[OK] - 5 fichiers ignorés (extension non autorisée)\n",
      "[OK] - Taille totale: 1091.79 MB\n",
      "[OK] - Dossier GCS: gs://bronze-sncf-etl/bronze/histo-validations-reseau-ferre/\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1.3 - Upload vers GCS\n",
    "print(f\"\\n[Upload] - Upload des données historiques vers GCS...\")\n",
    "upload_folder_to_gcs(BASE_DIR, gcs_folder=\"bronze\", gcs_subfolder=\"histo-validations-reseau-ferre\", extensions=[\".csv\", \".txt\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78959fd",
   "metadata": {},
   "source": [
    "# 2 - Ingestion des données d'emplacement des gares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bedf6498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[...] - Téléchargement du fichier Parquet emplacement-des-gares-idf...\n",
      "[OK] - Téléchargé: /Users/admin/Desktop/projects/m2-univ-reims-sep-cs-etl-sncf-gcp/data/emplacement-des-gares-idf/emplacement-des-gares-idf.parquet\n",
      "[OK] - Taille: 0.20 MB\n",
      "[...] - Upload de emplacement-des-gares-idf.parquet vers GCS...\n",
      "[OK] - Uploadé: gs://bronze-sncf-etl/bronze/emplacement-des-gares-idf/emplacement-des-gares-idf.parquet\n",
      "[OK] - Taille: 0.20 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'gs://bronze-sncf-etl/bronze/emplacement-des-gares-idf/emplacement-des-gares-idf.parquet'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2.1 - Récupération du fichier CSV depuis l'API ile de de France Mobilités\n",
    "dl_path_gares = download_parquet_from_idfm('emplacement-des-gares-idf')\n",
    "upload_to_gcs(file_path=dl_path_gares, gcs_folder=\"bronze\", gcs_subfolder=\"emplacement-des-gares-idf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0207667",
   "metadata": {},
   "source": [
    "# 3 - Ingestion des données lignes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b9ad319a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[...] - Téléchargement du fichier Parquet referentiel-des-lignes...\n",
      "[OK] - Téléchargé: /Users/admin/Desktop/projects/m2-univ-reims-sep-cs-etl-sncf-gcp/data/referentiel-des-lignes/referentiel-des-lignes.parquet\n",
      "[OK] - Taille: 0.17 MB\n",
      "[...] - Upload de referentiel-des-lignes.parquet vers GCS...\n",
      "[OK] - Uploadé: gs://bronze-sncf-etl/bronze/referentiel-des-lignes/referentiel-des-lignes.parquet\n",
      "[OK] - Taille: 0.17 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'gs://bronze-sncf-etl/bronze/referentiel-des-lignes/referentiel-des-lignes.parquet'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3.1 - Téléchargement direct du fichier Parquet depuis l'API IDFM\n",
    "dl_path_lignes = download_parquet_from_idfm('referentiel-des-lignes')\n",
    "upload_to_gcs(file_path=dl_path_lignes, gcs_folder=\"bronze\", gcs_subfolder=\"referentiel-des-lignes\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1944b8b4",
   "metadata": {},
   "source": [
    "# 4 - Ingestion des données Arrets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcae24ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[...] - Téléchargement du fichier Parquet arrets...\n",
      "[OK] - Téléchargé: /Users/admin/Desktop/projects/m2-univ-reims-sep-cs-etl-sncf-gcp/data/arrets/arrets.parquet\n",
      "[OK] - Taille: 2.76 MB\n",
      "[...] - Upload de arrets.parquet vers GCS...\n",
      "[OK] - Uploadé: gs://bronze-sncf-etl/bronze/arrets/arrets.parquet\n",
      "[OK] - Taille: 2.76 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'gs://bronze-sncf-etl/bronze/arrets/arrets.parquet'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4.1 - Téléchargement direct du fichier Parquet depuis l'API IDFM\n",
    "dl_path_arrets = download_parquet_from_idfm('arrets')\n",
    "upload_to_gcs(file_path=dl_path_arrets, gcs_folder=\"bronze\", gcs_subfolder=\"arrets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48372fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 - Ingestion Vacances Scolaires, Jours Fériés et Météo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "50f4c9e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[...] - Téléchargement des données de vacances scolaires...\n",
      "[OK] - Téléchargé: /Users/admin/Desktop/projects/m2-univ-reims-sep-cs-etl-sncf-gcp/data/vacances-scolaires/vacances_scolaires.csv\n",
      "[OK] - Taille: 0.23 MB\n",
      "[...] - Upload de vacances_scolaires.csv vers GCS...\n",
      "[OK] - Uploadé: gs://bronze-sncf-etl/bronze/vacances-scolaires/vacances_scolaires.csv\n",
      "[OK] - Taille: 0.23 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'gs://bronze-sncf-etl/bronze/vacances-scolaires/vacances_scolaires.csv'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5.1 - Vacances Scolaires\n",
    "URL = \"https://data.education.gouv.fr/explore/dataset/fr-en-calendrier-scolaire/download/?format=csv\"\n",
    "OUTPUT_FILE = \"vacances_scolaires.csv\"\n",
    "\n",
    "vacances_dir = DATA_DIR / \"vacances-scolaires\"\n",
    "vacances_dir.mkdir(exist_ok=True)\n",
    "csv_path = vacances_dir / OUTPUT_FILE\n",
    "\n",
    "print(f\"[...] - Téléchargement des données de vacances scolaires...\")\n",
    "response = requests.get(URL, timeout=120)\n",
    "response.raise_for_status()\n",
    "\n",
    "csv_path.write_bytes(response.content)\n",
    "\n",
    "file_size_mb = csv_path.stat().st_size / (1024 * 1024)\n",
    "print(f\"[OK] - Téléchargé: {csv_path}\")\n",
    "print(f\"[OK] - Taille: {file_size_mb:.2f} MB\")\n",
    "\n",
    "# Upload vers GCS\n",
    "upload_to_gcs(file_path=csv_path, gcs_folder=\"bronze\", gcs_subfolder=\"vacances-scolaires\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d23d2cbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[...] - Téléchargement des jours fériés de 2015 à 2026...\n",
      "[OK] - 2015: 11 jours fériés\n",
      "[...] - Upload de jours_feries_2015.json vers GCS...\n",
      "[OK] - Uploadé: gs://bronze-sncf-etl/bronze/jours-feries/jours_feries_2015.json\n",
      "[OK] - Taille: 0.00 MB\n",
      "[OK] - 2016: 11 jours fériés\n",
      "[...] - Upload de jours_feries_2016.json vers GCS...\n",
      "[OK] - Uploadé: gs://bronze-sncf-etl/bronze/jours-feries/jours_feries_2016.json\n",
      "[OK] - Taille: 0.00 MB\n",
      "[OK] - 2017: 11 jours fériés\n",
      "[...] - Upload de jours_feries_2017.json vers GCS...\n",
      "[OK] - Uploadé: gs://bronze-sncf-etl/bronze/jours-feries/jours_feries_2017.json\n",
      "[OK] - Taille: 0.00 MB\n",
      "[OK] - 2018: 11 jours fériés\n",
      "[...] - Upload de jours_feries_2018.json vers GCS...\n",
      "[OK] - Uploadé: gs://bronze-sncf-etl/bronze/jours-feries/jours_feries_2018.json\n",
      "[OK] - Taille: 0.00 MB\n",
      "[OK] - 2019: 11 jours fériés\n",
      "[...] - Upload de jours_feries_2019.json vers GCS...\n",
      "[OK] - Uploadé: gs://bronze-sncf-etl/bronze/jours-feries/jours_feries_2019.json\n",
      "[OK] - Taille: 0.00 MB\n",
      "[OK] - 2020: 11 jours fériés\n",
      "[...] - Upload de jours_feries_2020.json vers GCS...\n",
      "[OK] - Uploadé: gs://bronze-sncf-etl/bronze/jours-feries/jours_feries_2020.json\n",
      "[OK] - Taille: 0.00 MB\n",
      "[OK] - 2021: 11 jours fériés\n",
      "[...] - Upload de jours_feries_2021.json vers GCS...\n",
      "[OK] - Uploadé: gs://bronze-sncf-etl/bronze/jours-feries/jours_feries_2021.json\n",
      "[OK] - Taille: 0.00 MB\n",
      "[OK] - 2022: 11 jours fériés\n",
      "[...] - Upload de jours_feries_2022.json vers GCS...\n",
      "[OK] - Uploadé: gs://bronze-sncf-etl/bronze/jours-feries/jours_feries_2022.json\n",
      "[OK] - Taille: 0.00 MB\n",
      "[OK] - 2023: 11 jours fériés\n",
      "[...] - Upload de jours_feries_2023.json vers GCS...\n",
      "[OK] - Uploadé: gs://bronze-sncf-etl/bronze/jours-feries/jours_feries_2023.json\n",
      "[OK] - Taille: 0.00 MB\n",
      "[OK] - 2024: 11 jours fériés\n",
      "[...] - Upload de jours_feries_2024.json vers GCS...\n",
      "[OK] - Uploadé: gs://bronze-sncf-etl/bronze/jours-feries/jours_feries_2024.json\n",
      "[OK] - Taille: 0.00 MB\n",
      "[OK] - 2025: 11 jours fériés\n",
      "[...] - Upload de jours_feries_2025.json vers GCS...\n",
      "[OK] - Uploadé: gs://bronze-sncf-etl/bronze/jours-feries/jours_feries_2025.json\n",
      "[OK] - Taille: 0.00 MB\n",
      "[OK] - 2026: 11 jours fériés\n",
      "[...] - Upload de jours_feries_2026.json vers GCS...\n",
      "[OK] - Uploadé: gs://bronze-sncf-etl/bronze/jours-feries/jours_feries_2026.json\n",
      "[OK] - Taille: 0.00 MB\n",
      "\n",
      "[OK] - Terminé: /Users/admin/Desktop/projects/m2-univ-reims-sep-cs-etl-sncf-gcp/data/jours-feries\n"
     ]
    }
   ],
   "source": [
    "# 5.2 - Jours Fériés (API Gouv) - Plusieurs années\n",
    "start_year = 2015\n",
    "end_year = datetime.now().year + 1\n",
    "\n",
    "feries_dir = DATA_DIR / \"jours-feries\"\n",
    "feries_dir.mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"[...] - Téléchargement des jours fériés de {start_year} à {end_year}...\")\n",
    "\n",
    "for year in range(start_year, end_year + 1):\n",
    "    URL = f\"https://calendrier.api.gouv.fr/jours-feries/metropole/{year}.json\"\n",
    "    json_path = feries_dir / f\"jours_feries_{year}.json\"\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(URL, timeout=60)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        feries = response.json()\n",
    "        json_path.write_text(json.dumps(feries, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
    "        \n",
    "        print(f\"[OK] - {year}: {len(feries)} jours fériés\")\n",
    "        \n",
    "        # Upload vers GCS\n",
    "        upload_to_gcs(file_path=json_path, gcs_folder=\"bronze\", gcs_subfolder=\"jours-feries\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"[Erreur] - {year}: {e}\")\n",
    "\n",
    "print(f\"\\n[OK] - Terminé: {feries_dir}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "etl-gcp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
